{
  "id": "VOICE",
  "title": "Voice Interface (ElevenLabs MVP)",
  "priority": "Should Have",
  "effort": "L",
  "status": "Spec'd",
  "sprint": "Backlog",
  "depends_on": [
    "ONBOARD"
  ],
  "spec": "## Voice Interface (ElevenLabs MVP)\n\n### Goal\nAllow users to interact with the AI strategist via voice — speak questions, hear responses — for a more natural strategy session experience.\n\n### Scope\n- **Speech-to-text**: Browser Web Speech API (free) or Whisper API\n- **Text-to-speech**: ElevenLabs API with a professional voice\n- **Push-to-talk**: Hold spacebar or click mic button to speak\n- **Voice responses**: AI responses are both displayed as text and spoken aloud\n- **Settings**: Voice on/off toggle, voice selection, speed control\n\n### Technical Approach\n- `useVoiceInput()` hook: manages Web Speech API / Whisper\n- `useVoiceOutput()` hook: manages ElevenLabs streaming TTS\n- Backend proxy: `/api/tts` to avoid exposing ElevenLabs API key\n- Audio player: streaming playback with cancel on new input\n- Depends on ONBOARD (voice is especially powerful for discovery flow)\n\n### Acceptance Criteria\n- Given the user holds the mic button and speaks, their speech is transcribed and sent as a chat message\n- Given the AI responds, the response is spoken aloud with natural intonation\n- Given the user toggles voice off, only text chat is used",
  "created": "2026-02-23",
  "updated": "2026-02-23"
}